# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
train     : .datasets/coco/train2017.txt  
val       : .datasets/coco/val2017.txt  
test      : .datasets/coco/test-dev2017.txt 
device    : 0                         # cuda device, i.e. 0 or 0,1,2,3 or cpu

# number of classes
nc        : 6
# class names
names     : [ "Pedestrian", "Cyclist", "Car", "Truck", "Tram", "Tricycle" ]
# coco
# names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
#          'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
#          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
#          'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
#          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
#          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
#          'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
#          'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
#          'hair drier', 'toothbrush' ]

# saving results to wandb and local dir
wandb     : False            # save results to weights and bias
project   : SSLAD-2D     # results will be saved to runs/project/run_name
run_name  : yolov7

train :
    weights       : weights/yolov9/yolov9-c-converted.pt # model.pt path [yolov9-c-converted.pt , yolov9-e-converted.pt ]
    cfg           : None                      # model.yaml path
    data          : data/coco.yaml            # data.yaml path
    hyp           : data/hyp.scratch.p5.yaml  # hyperparameters path
    epochs        : 100                       # num of epochs
    batch-size    : 16                        # total batch size for all GPUs
    img-size      : [640, 640]                # [train, test] image sizes
    rect          : False                     # rectangular training
    resume        : False                     # resume most recent training
    nosave        : False                     # only save final checkpoint
    notest        : False                     # only test final epoch
    noautoanchor  : False                     # disable autoanchor check
    evolve        : False                     # evolve hyperparameters
    bucket        : None                      # gsutil bucket
    cache-images  : False                     # cache images for faster training
    image-weights : False                     # use weighted image selection for training
    multi-scale   : False                     # vary img-size +/- 50%%
    single-cls    : False                     # train multi-class data as single-class
    adam          : False                     # use torch.optim.Adam() optimizer
    sync-bn       : False                     # use SyncBatchNorm, only available in DDP mode
    local_rank    : -1                        # DDP parameter, do not modify
    workers       : 8                         # maximum number of dataloader workers
    project       : runs/train                # save to project/name
    entity        : None                      # W&B entity
    name          : exp                       # save to project/name
    exist-ok      : False                     # existing project/name ok, do not increment
    quad          : False                     # quad dataloader
    linear-lr     : False                     # linear LR
    label-smoothing : 0.0                     # Label smoothing epsilon
    upload_dataset: False                     # Upload dataset as W&B artifact table
    bbox_interval : -1                        # Set bounding-box image logging interval for W&B
    save_period   : -1                        # Log model after every "save_period" epoch
    artifact_alias: latest                    # version of dataset artifact to be used
    freeze        : [0]                       # Freeze layers: backbone of yolov7=50, first3=0 1 2
    v5-metric     : False                     # assume maximum recall as 1.0 in AP calculation

test : 
    weights      : weights/yolov9/yolov9-c-converted.pt     # model.pt path [yolov9-c-converted.pt , yolov9-e-converted.pt ]
    data         : data/coco.yaml # *.data path
    batch-size   : 32             # size of each image batch
    img-size     : 640            # inference size (pixels)
    conf-thres   : 0.001          # object confidence threshold
    iou-thres    : 0.65           # IOU threshold for NMS
    task         : val            # train, val, test, speed or study
    single-cls   : False          # treat as single-class dataset
    augment      : False          # augmented inference
    verbose      : False          # report mAP by class
    save-txt     : False          # save results to *.txt
    save-hybrid  : False          # save label+prediction hybrid results to *.txt
    save-conf    : False          # save confidences in --save-txt labels
    save-json    : False          # save a cocoapi-compatible JSON results file
    no-trace     : True           # don`t trace model
    v5-metric    : False          # assume maximum recall as 1.0 in AP calculation

inference  :
    weights     : weights/yolov9/yolov9-c-converted.pt    # model.pt path [yolov9-c-converted.pt , yolov9-e-converted.pt ]
    source      : datasets/demo.jpg  # source file/folder, 0 for webcam
    data        : data/coco128.yaml # (optional) dataset.yaml path
    device      : 0                 # cuda device, i.e. 0 or 0,1,2,3 or cpu
    imgsz       : [640]             # inference size (pixels)
    conf_thres  : 0.25              # object confidence threshold
    iou_thres   : 0.45              # IOU threshold for NMS'
    max_det     : 1000              # maximum detections per image
    view_img    : True              # display results
    save_txt    : False             # save results to *.txt
    save_conf   : False             # save confidences in --save-txt labels
    save_crop   : False             # save cropped prediction boxes
    nosave      : False             # do not save images/videos
    classes     :                   # filter by class: --class 0, or --class 0 2 3
    agnostic_nms  : None            # class-agnostic NMS
    augment     : False             # augmented inference
    visualize   :                   # visualize features
    update      : False             # update all models
    no_trace    : True              # don`t trace model
    line_thickness : 1               # bounding box thickness (pixels)
    hide_labels : False             # hide labels
    hide_conf   : False             # hide confidences
    half        : False             # use FP16 half-precision inference
    dnn         : False             # use OpenCV DNN for ONNX inference
    vid_stride  : 1                 # video frame-rate stride
